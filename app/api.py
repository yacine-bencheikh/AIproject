from dotenv import load_dotenv

load_dotenv()
import re
import os
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from groq import Client
from fastapi.encoders import jsonable_encoder
import json
from langchain_community.llms import Ollama


router = APIRouter()


class QueryRequest(BaseModel):
    question: str


# Fonction de nettoyage du texte
def clean_text(text):
    text = re.sub(
        r"\s+", " ", text
    )  # Suppression des espaces et sauts de ligne excessifs
    return text.strip()  # Suppression des espaces en d√©but/fin


# Liste des documents juridiques √† indexer
documents = [
    {
        "path": "app\documents\Article-TAYAA 16oct19.pdf",
        "title": "Diagnostic et prise en charge de la d√©pression chez lesujet √¢g√©",
    },
    {
        "path": "app\documents\BAT-Depression-check_21.02.22.pdf",
        "title": "Mieux vivre avec la d√©pression",
    },
    {
        "path": "app\documents\digno.pdf",
        "title": "Diagnostic en psychiatrie adulte Mieux comprendre et √™tre accompagn√©",
    },
    {
        "path": "app\documents\map_enfants_2008.pdf",
        "title": "Le bon usage des antid√©presseurs chez l‚Äôenfant et l‚Äôadolescent",
    },
    {
        "path": "app\documents\PSYCOM_Brochures-A5_TP_Troubles-depressifs_2025_WEB.pdf",
        "title": "Troubles d√©pressifs TROUBLES PSYCHIQUES",
    },
    
    # Ajouter d'autres documents ici...
]


# Initialisation de la liste des documents trait√©s
all_docs = []


# Chargement et traitement des documents
for doc in documents:
    pdf_path = doc["path"]
    title = doc["title"]

    if not os.path.exists(pdf_path):
        print(f"‚ö†Ô∏è Attention : {pdf_path} non trouv√©, il sera ignor√©.")
        continue

    loader = PyPDFLoader(pdf_path)
    pages = loader.load()

    for page_num, page in enumerate(pages):
        cleaned_text = clean_text(page.page_content)
        all_docs.append(
            {
                "text": cleaned_text,
                "metadata": {"source": pdf_path, "title": title, "page": page_num + 1},
            }
        )


# D√©coupage du texte en chunks avec inclusion des m√©tadonn√©es
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = [
    (chunk, doc["metadata"])
    for doc in all_docs
    for chunk in text_splitter.split_text(doc["text"])
]


# Cr√©ation d'objets Documents avec m√©tadonn√©es
from langchain.schema import Document

final_docs = [
    Document(page_content=chunk, metadata=metadata) for chunk, metadata in docs
]


# Chargement du mod√®le d'embeddings
persist_directory = "MyVectorDB1.0"
embedding_function = HuggingFaceEmbeddings(
    model_name="sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
)


# Cr√©ation ou chargement de la base Chroma avec m√©tadonn√©es
vectorstore = Chroma.from_documents(
    final_docs, embedding_function, persist_directory=persist_directory
)


# Configuration de la cl√© API Groq
api_key = os.getenv("GROQ_API_KEY")
if not api_key:
    raise ValueError("La cl√© API GROQ_API_KEY n'est pas d√©finie.")


client = Client(api_key=api_key)


# Initialisation du mod√®le Groq
groq_llm = ChatGroq(model_name="llama-3.3-70b-versatile")
# ollama_llm = Ollama(model="mistral")


# D√©finition du prompt personnalis√©
template =  """
Tu es un **Psychiatre sp√©cialis√© en troubles de l‚Äôhumeur**.  
Ton r√¥le :  
1. **Recueillir** : √Çge, sexe, ant√©c√©dents m√©dicaux/familiaux.  
2. **√âvaluer** : Sympt√¥mes (crit√®res DSM-5/ICD-10), dur√©e, impact sur la vie quotidienne.  
3. **Diagnostiquer** : D√©pression l√©g√®re/moder√©e/s√©v√®re, trouble bipolaire, etc.  
4. **Orienter** : Vers un psychiatre en pr√©sentiel si risque suicidaire ou cas complexe.  

### **Contexte Scientifique** :  
{context}  

### **Historique Conversationnel** :  
{chat_history}  

### **Patient** : {question}  

### **R√©ponse Structur√©e** (en Markdown) :  
1. **√âvaluation** :  
   - Sympt√¥mes cl√©s : [liste]  
   - √âchelle PHQ-9/GAD-7 (si applicable) : [score estim√©]  
2. **Hypoth√®se Diagnostique** :  
   - [Diagnostic pr√©liminaire + crit√®res]  
3. **Recommandations** :  
   - Consultation en pr√©sentiel : [Oui/Non]  
   - Ressources : [Lignes d‚Äô√©coute, centres sp√©cialis√©s]  
4. **Disclaimer** : *"Ceci n‚Äôest pas un avis m√©dical d√©finitif. Consultez un professionnel."*  
"""


prompt_template = PromptTemplate(
    input_variables=["history", "context", "question"],
    template=template,
)


# Initialisation de la m√©moire de conversation
memory = ConversationBufferMemory(
    memory_key="chat_history", return_messages=True, input_key="question"
)


# Cr√©ation de la cha√Æne QA avec m√©moire et r√©cup√©ration des sources
qa_chain = RetrievalQA.from_chain_type(
    llm=groq_llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),  # R√©cup√©ration des 5 documents les plus pertinents
    return_source_documents=True,
    verbose=True,
    chain_type_kwargs={"prompt": prompt_template, "memory": memory, "verbose": True}
)


@router.post("/chatPsy")
def chat(request: QueryRequest):
    try:
        response = qa_chain({"query": request.question})  # Ex√©cute la requ√™te
        answer = response["result"]

        # üîç Debugging: Afficher les sources
        print("üîç Raw source documents:", response["source_documents"])

        # Extraction des sources avec m√©tadonn√©es
        sources = []
        for doc in response["source_documents"]:
            print(
                "üìù Metadata:", doc.metadata
            )  # Debugging : voir les m√©tadonn√©es r√©elles
            sources.append(
                {
                    "source": doc.metadata.get("source", "Inconnu"),
                    "title": doc.metadata.get("title", "Inconnu"),
                    "page": doc.metadata.get("page", "Inconnue"),
                }
            )

        # üîç Debugging: Afficher la structure des sources avant retour
        print(
            "‚úÖ Formatted sources:", json.dumps(sources, indent=2, ensure_ascii=False)
        )

        return jsonable_encoder({"response": answer, "sources": sources})

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
